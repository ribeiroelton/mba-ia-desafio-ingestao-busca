# [011] - Otimizar Suite de Testes: Reduzir Custo e Tempo de Execu√ß√£o

## Metadados
- **ID**: 011
- **Grupo**: Fase 3 - Qualidade e Entrega
- **Prioridade**: Alta
- **Complexidade**: M√©dia
- **Estimativa**: 2 dias

## Descri√ß√£o

Otimizar a suite de testes do projeto reduzindo o n√∫mero de testes unit√°rios redundantes e focando em testes de integra√ß√£o end-to-end que validem o comportamento real do sistema. O objetivo √© reduzir tempo de execu√ß√£o e custo com APIs (OpenAI) mantendo cobertura de qualidade.

**Situa√ß√£o Atual**:
- 48 testes totais (38 unit√°rios + 10 integra√ß√£o)
- Muitos testes unit√°rios com mocks que n√£o validam comportamento real
- Testes de chat com mocks do LLM n√£o validam respostas reais
- Tempo de execu√ß√£o: ~84 segundos
- Custo de APIs n√£o otimizado

**Situa√ß√£o Desejada**:
- ~20-25 testes totais (m√°ximo 30)
- Foco em testes de integra√ß√£o E2E
- Valida√ß√£o com gpt-5-nano real (custo otimizado)
- Tempo de execu√ß√£o: ~40-50 segundos
- Cobertura >= 85%
- Menor custo total com APIs

## Requisitos

### Requisitos Funcionais
- RF-027: Suite de testes otimizada com foco em integra√ß√£o
- RF-028: Valida√ß√£o com LLM real (gpt-5-nano)
- RF-029: Cobertura de c√≥digo >= 85%

### Requisitos N√£o-Funcionais
- RNF-021: Tempo de execu√ß√£o reduzido em ~40%
- RNF-022: Custo com APIs reduzido
- RNF-023: Testes mais confi√°veis (menos mocks)
- RNF-024: Facilidade de manuten√ß√£o

## Fonte da Informa√ß√£o

### Contexto Atual
- **Suite Atual**: 48 testes (38 unit√°rios + 10 integra√ß√£o)
- **Testes com Mocks**: 7 testes de chat com ChatOpenAI mockado
- **Testes Redundantes**: M√∫ltiplos testes validando mesma funcionalidade
- **Modelo LLM**: Deve usar gpt-5-nano (custo otimizado)

### Regras de Neg√≥cio Cr√≠ticas
- **RN-001**: Respostas baseadas EXCLUSIVAMENTE no contexto
- **RN-002**: Mensagem padr√£o quando sem contexto
- **RN-006**: Busca retorna k=10 resultados

## Stack Necess√°ria

- **Python**: 3.13.9+
- **Pytest**: 8.3.4
- **pytest-cov**: Para cobertura
- **LangChain**: 0.3.27
- **OpenAI**: gpt-5-nano (modelo de teste otimizado)
- **PostgreSQL**: 17 com pgVector (TestContainers ou Docker)

## Depend√™ncias

### Depend√™ncias T√©cnicas
- Tarefa 009: Valida√ß√£o de testes conclu√≠da
- Tarefa 010: README atualizado
- Docker/Docker Compose funcionando
- OpenAI API Key configurada
- gpt-5-nano dispon√≠vel

### Depend√™ncias de Ambiente
- `.env` com `LLM_MODEL=gpt-5-nano`
- `OPENAI_API_KEY` configurada
- PostgreSQL rodando (docker-compose up)

## Crit√©rios de Aceite

1. [ ] Reduzir de 48 para m√°ximo 30 testes
2. [ ] M√≠nimo 70% dos testes devem ser de integra√ß√£o E2E
3. [ ] Eliminar todos os mocks de ChatOpenAI
4. [ ] Usar gpt-5-nano em todos os testes que requerem LLM
5. [ ] Cobertura de c√≥digo >= 85%
6. [ ] Tempo de execu√ß√£o <= 50 segundos
7. [ ] Todos os testes passando
8. [ ] Validar RN-001 e RN-002 com LLM real
9. [ ] Reduzir testes unit√°rios de formata√ß√£o/valida√ß√£o simples
10. [ ] Manter testes cr√≠ticos de regras de neg√≥cio

## Implementa√ß√£o Resumida

### An√°lise da Suite Atual

#### Testes a REMOVER (Redundantes ou de Baixo Valor)

**test_chat.py** (remover 4-5 testes):
- `test_build_prompt_format`: Valida√ß√£o trivial de string
- `test_build_prompt_with_special_characters`: Coberto por integra√ß√£o
- `test_build_prompt_with_multiline_context`: Coberto por integra√ß√£o
- `test_build_prompt_empty_context`: Valida√ß√£o trivial
- `test_system_prompt_has_required_rules`: Valida√ß√£o de constante

**test_ingest.py** (remover 3-4 testes):
- `test_load_pdf_invalid_extension`: Valida√ß√£o trivial
- `test_split_documents_single_small_document`: Redundante
- `test_split_documents_preserves_metadata`: Coberto por integra√ß√£o
- `test_store_in_vectorstore_empty_chunks`: Caso de erro raro

**test_search.py** (remover 4-5 testes):
- `test_semantic_search_with_custom_collection`: Redundante
- `test_search_k_respects_env_variable`: Configura√ß√£o simples
- `test_get_context_format`: Valida√ß√£o trivial de string
- `test_search_with_special_characters`: Coberto por integra√ß√£o
- `test_vectorstore_connection_error`: Mock de erro de conex√£o

**Total a remover**: 11-14 testes unit√°rios

#### Testes a MANTER e MELHORAR

**Testes Unit√°rios Cr√≠ticos** (8-10 testes):
- Valida√ß√£o de entrada (query vazia, arquivo inexistente)
- L√≥gica de chunking (tamanho, overlap)
- Configura√ß√µes cr√≠ticas (k=10 fixo)
- Tratamento de erros de neg√≥cio

**Testes de Integra√ß√£o E2E** (15-20 testes):
- Fluxo completo: Ingest ‚Üí Search ‚Üí Chat com LLM real
- Valida√ß√£o RN-001: Pergunta com contexto (LLM real)
- Valida√ß√£o RN-002: Pergunta sem contexto (LLM real)
- Valida√ß√£o RN-006: k=10 resultados
- Cen√°rios cr√≠ticos com dados reais

### Estrutura de Arquivos Otimizada

```
tests/
‚îú‚îÄ‚îÄ conftest.py                      # Fixtures compartilhadas
‚îú‚îÄ‚îÄ unit/                            # Testes unit√°rios cr√≠ticos (8-10)
‚îÇ   ‚îú‚îÄ‚îÄ test_ingest_validation.py    # Valida√ß√µes de entrada
‚îÇ   ‚îú‚îÄ‚îÄ test_search_validation.py    # Valida√ß√µes de busca
‚îÇ   ‚îî‚îÄ‚îÄ test_chat_validation.py      # Valida√ß√µes b√°sicas
‚îî‚îÄ‚îÄ integration/                     # Testes E2E (15-20)
    ‚îú‚îÄ‚îÄ test_e2e_core.py            # Fluxos principais
    ‚îú‚îÄ‚îÄ test_business_rules.py      # RN-001, RN-002, RN-006
    ‚îî‚îÄ‚îÄ test_real_scenarios.py      # Cen√°rios reais com gpt-5-nano
```

### Componentes a Implementar

#### 1. Configura√ß√£o para gpt-5-nano

**Arquivo**: `tests/conftest.py`

```python
import os
import pytest
from dotenv import load_dotenv

load_dotenv()

@pytest.fixture(scope="session", autouse=True)
def setup_llm_model():
    """Garante que gpt-5-nano √© usado em todos os testes."""
    os.environ["LLM_MODEL"] = "gpt-5-nano"
    yield
    
@pytest.fixture
def gpt5_nano_model():
    """Retorna nome do modelo para testes."""
    return "gpt-5-nano"
```

#### 2. Testes Unit√°rios Cr√≠ticos

**Arquivo**: `tests/unit/test_ingest_validation.py`

```python
"""Testes unit√°rios cr√≠ticos para valida√ß√£o de ingest√£o."""
import pytest
from src.ingest import load_pdf, split_documents

def test_load_pdf_file_not_found():
    """Valida erro quando arquivo n√£o existe."""
    with pytest.raises(FileNotFoundError):
        load_pdf("naoexiste.pdf")

def test_split_documents_chunk_size():
    """Valida que chunks respeitam tamanho m√°ximo (RN-005)."""
    from langchain_core.documents import Document
    
    text = "A" * 3000
    docs = [Document(page_content=text)]
    chunks = split_documents(docs)
    
    # Chunks <= 1000 caracteres
    assert all(len(c.page_content) <= 1000 for c in chunks)
    assert len(chunks) >= 3  # M√≠nimo esperado para 3000 chars

def test_split_documents_overlap():
    """Valida overlap de 150 caracteres (RN-005)."""
    # Implementar valida√ß√£o de overlap
    pass
```

**Arquivo**: `tests/unit/test_search_validation.py`

```python
"""Testes unit√°rios cr√≠ticos para valida√ß√£o de busca."""
import pytest
from src.search import SemanticSearch

def test_search_empty_query():
    """Valida erro com query vazia."""
    searcher = SemanticSearch()
    
    with pytest.raises(ValueError, match="Query n√£o pode ser vazia"):
        searcher.search("")

def test_search_k_fixed_10():
    """Valida que k=10 √© fixo (RN-006)."""
    searcher = SemanticSearch()
    assert searcher.k == 10
```

**Arquivo**: `tests/unit/test_chat_validation.py`

```python
"""Testes unit√°rios cr√≠ticos para valida√ß√£o de chat."""
from src.chat import build_prompt, SYSTEM_PROMPT

def test_system_prompt_contains_rules():
    """Valida que SYSTEM_PROMPT cont√©m regras cr√≠ticas."""
    assert "EXCLUSIVAMENTE" in SYSTEM_PROMPT
    assert "N√£o tenho informa√ß√µes necess√°rias" in SYSTEM_PROMPT

def test_build_prompt_structure():
    """Valida estrutura do prompt."""
    context = "Contexto de teste"
    question = "Pergunta teste"
    
    prompt = build_prompt(context, question)
    
    assert "CONTEXTO:" in prompt
    assert context in prompt
    assert question in prompt
```

#### 3. Testes de Integra√ß√£o E2E com LLM Real

**Arquivo**: `tests/integration/test_business_rules.py`

```python
"""Testes de integra√ß√£o para regras de neg√≥cio com LLM real."""
import pytest
from src.ingest import load_pdf, split_documents, store_in_vectorstore
from src.search import SemanticSearch
from src.chat import ask_llm

@pytest.fixture(scope="module")
def ingested_test_doc(sample_pdf_path, clean_test_collection):
    """Ingere documento de teste uma vez para todos os testes."""
    docs = load_pdf(sample_pdf_path)
    chunks = split_documents(docs)
    store_in_vectorstore(chunks, "test_business_rules")
    yield
    # Cleanup ap√≥s todos os testes do m√≥dulo

def test_rn001_answer_with_context(ingested_test_doc):
    """
    RN-001: Respostas baseadas EXCLUSIVAMENTE no contexto.
    
    Cen√°rio: Documento cont√©m informa√ß√£o espec√≠fica
    Query: Pergunta sobre informa√ß√£o presente
    Expected: Resposta correta baseada no documento (LLM real)
    """
    searcher = SemanticSearch(collection_name="test_business_rules")
    context = searcher.get_context("Qual informa√ß√£o est√° no documento?")
    
    # Usar gpt-5-nano REAL
    response = ask_llm(
        question="Qual informa√ß√£o est√° no documento?",
        context=context
    )
    
    # Valida√ß√µes
    assert isinstance(response, str)
    assert len(response) > 0
    # Resposta n√£o deve ser mensagem padr√£o
    assert "N√£o tenho informa√ß√µes necess√°rias" not in response

def test_rn002_no_context_standard_message(ingested_test_doc):
    """
    RN-002: Mensagem padr√£o quando informa√ß√£o n√£o dispon√≠vel.
    
    Cen√°rio: Pergunta completamente fora do contexto
    Query: "Qual √© a capital da Fran√ßa?" (n√£o est√° no doc)
    Expected: "N√£o tenho informa√ß√µes necess√°rias..." (LLM real)
    """
    searcher = SemanticSearch(collection_name="test_business_rules")
    context = searcher.get_context("Qual √© a capital da Fran√ßa?")
    
    # Usar gpt-5-nano REAL
    response = ask_llm(
        question="Qual √© a capital da Fran√ßa?",
        context=context
    )
    
    # Validar mensagem padr√£o
    assert "N√£o tenho informa√ß√µes necess√°rias" in response

def test_rn006_search_returns_k10(ingested_test_doc):
    """
    RN-006: Busca retorna exatamente 10 resultados (k=10).
    
    Expected: M√°ximo 10 chunks retornados
    """
    searcher = SemanticSearch(collection_name="test_business_rules")
    results = searcher.search("teste query gen√©rica")
    
    assert len(results) <= 10
    assert searcher.k == 10
```

**Arquivo**: `tests/integration/test_e2e_core.py`

```python
"""Testes E2E do fluxo completo com LLM real."""
import pytest
from src.ingest import load_pdf, split_documents, store_in_vectorstore
from src.search import SemanticSearch
from src.chat import ask_llm

def test_e2e_complete_flow_with_real_llm(sample_pdf_path, clean_test_collection):
    """
    Teste E2E completo: Ingest ‚Üí Search ‚Üí Chat com gpt-5-nano real.
    
    Fluxo:
    1. Ingerir PDF
    2. Buscar contexto relevante
    3. Gerar resposta com LLM real
    4. Validar resposta
    """
    # 1. Ingest√£o
    docs = load_pdf(sample_pdf_path)
    chunks = split_documents(docs)
    store_in_vectorstore(chunks, "test_e2e_core")
    
    assert len(chunks) > 0
    
    # 2. Busca
    searcher = SemanticSearch(collection_name="test_e2e_core")
    context = searcher.get_context("Qual √© o conte√∫do principal?")
    
    assert len(context) > 0
    
    # 3. Chat com LLM REAL (gpt-5-nano)
    response = ask_llm(
        question="Qual √© o conte√∫do principal?",
        context=context
    )
    
    # 4. Valida√ß√µes
    assert isinstance(response, str)
    assert len(response) > 10  # Resposta substantiva
    assert response != ""

def test_e2e_multiple_queries_same_session(sample_pdf_path, clean_test_collection):
    """
    Teste E2E: M√∫ltiplas queries na mesma sess√£o.
    
    Valida:
    - Consist√™ncia de resultados
    - Performance de queries sequenciais
    - Qualidade de respostas com LLM real
    """
    # Setup
    docs = load_pdf(sample_pdf_path)
    chunks = split_documents(docs)
    store_in_vectorstore(chunks, "test_multiple_queries")
    
    searcher = SemanticSearch(collection_name="test_multiple_queries")
    
    # Query 1: Com contexto
    context1 = searcher.get_context("Primeira pergunta sobre o documento")
    response1 = ask_llm("Primeira pergunta sobre o documento", context1)
    
    assert len(response1) > 0
    
    # Query 2: Sem contexto (fora do doc)
    context2 = searcher.get_context("Qual √© a capital do Brasil?")
    response2 = ask_llm("Qual √© a capital do Brasil?", context2)
    
    assert "N√£o tenho informa√ß√µes necess√°rias" in response2
    
    # Query 3: Com contexto novamente
    context3 = searcher.get_context("Terceira pergunta sobre o documento")
    response3 = ask_llm("Terceira pergunta sobre o documento", context3)
    
    assert len(response3) > 0
```

**Arquivo**: `tests/integration/test_real_scenarios.py`

```python
"""Testes de cen√°rios reais com gpt-5-nano."""
import pytest
from src.ingest import load_pdf, split_documents, store_in_vectorstore
from src.search import SemanticSearch
from src.chat import ask_llm

@pytest.fixture(scope="module")
def real_scenario_collection(sample_pdf_path):
    """Setup para cen√°rios reais."""
    docs = load_pdf(sample_pdf_path)
    chunks = split_documents(docs)
    store_in_vectorstore(chunks, "real_scenarios")
    yield "real_scenarios"

def test_scenario_ambiguous_question(real_scenario_collection):
    """
    Cen√°rio: Pergunta amb√≠gua que requer interpreta√ß√£o.
    
    Expected: LLM real interpreta contexto e responde adequadamente
    """
    searcher = SemanticSearch(collection_name=real_scenario_collection)
    context = searcher.get_context("Me fale sobre isso")
    
    response = ask_llm("Me fale sobre isso", context)
    
    # LLM deve responder baseado no contexto ou informar falta de clareza
    assert len(response) > 0
    assert isinstance(response, str)

def test_scenario_llm_follows_system_prompt(real_scenario_collection):
    """
    Cen√°rio: Validar que LLM segue SYSTEM_PROMPT.
    
    Query sobre algo fora do contexto deve retornar mensagem padr√£o.
    """
    searcher = SemanticSearch(collection_name=real_scenario_collection)
    
    # Perguntas claramente fora do contexto
    out_of_context_questions = [
        "Quem foi o primeiro presidente dos Estados Unidos?",
        "Como fazer um bolo de chocolate?",
        "Qual √© a f√≥rmula da √°gua?"
    ]
    
    for question in out_of_context_questions:
        context = searcher.get_context(question)
        response = ask_llm(question, context)
        
        # LLM DEVE seguir SYSTEM_PROMPT
        assert "N√£o tenho informa√ß√µes necess√°rias" in response, \
            f"LLM n√£o seguiu SYSTEM_PROMPT para: {question}"

def test_scenario_context_length_handling(real_scenario_collection):
    """
    Cen√°rio: Query que retorna muito contexto (k=10 chunks).
    
    Expected: LLM processa contexto completo e responde adequadamente
    """
    searcher = SemanticSearch(collection_name=real_scenario_collection)
    
    # Query gen√©rica que deve retornar m√∫ltiplos chunks
    context = searcher.get_context("resumo completo")
    
    # Contexto deve conter m√∫ltiplos chunks
    assert "[Chunk" in context  # Formato esperado
    
    response = ask_llm("Fa√ßa um resumo do conte√∫do", context)
    
    # LLM deve processar e resumir
    assert len(response) > 50
    assert isinstance(response, str)
```

### Otimiza√ß√µes de Performance

#### 1. Fixtures com Escopo de M√≥dulo

```python
# tests/conftest.py

@pytest.fixture(scope="module")
def shared_test_collection():
    """
    Cria cole√ß√£o de teste uma vez por m√≥dulo.
    
    Reduz tempo de setup repetido.
    """
    collection_name = f"test_{uuid.uuid4().hex[:8]}"
    # Setup
    yield collection_name
    # Cleanup
```

#### 2. Paraleliza√ß√£o de Testes

```bash
# pytest.ini
[pytest]
addopts = -n auto  # pytest-xdist para paraleliza√ß√£o
```

#### 3. Cache de Embeddings (Futuro)

```python
# Considerar cache de embeddings para queries repetidas
# em ambiente de teste (n√£o implementar agora)
```

### Regras de Neg√≥cio a Implementar

- **RN-001**: Validar com LLM REAL que respostas s√£o baseadas no contexto
- **RN-002**: Validar com LLM REAL mensagem padr√£o quando sem contexto
- **RN-006**: Validar k=10 em testes de integra√ß√£o

### Valida√ß√µes Necess√°rias

1. **Valida√ß√£o de Custo**:
   - Contar chamadas de API por teste
   - Estimar custo total da suite
   - Validar uso de gpt-5-nano (mais barato)

2. **Valida√ß√£o de Tempo**:
   - Tempo total <= 50 segundos
   - Testes unit√°rios: < 5 segundos total
   - Testes integra√ß√£o: < 45 segundos total

3. **Valida√ß√£o de Cobertura**:
   - Cobertura >= 85%
   - Todas as fun√ß√µes cr√≠ticas cobertas
   - Regras de neg√≥cio cobertas

### Tratamento de Erros

1. **Erro de API OpenAI**:
   - Skip test se API indispon√≠vel (usar `pytest.mark.skipif`)
   - Retry autom√°tico (1 tentativa)
   - Mensagem clara de erro

2. **Timeout de LLM**:
   - Timeout de 30 segundos por chamada
   - Falhar gracefully com mensagem clara

3. **Erro de Conex√£o com Banco**:
   - Verificar PostgreSQL antes de rodar testes
   - Skip testes de integra√ß√£o se banco indispon√≠vel

## Testes de Qualidade e Cobertura

### Valida√ß√£o Pr√©-Otimiza√ß√£o

```bash
# Executar suite atual e medir
pytest tests/ -v --durations=10 --cov=src --cov-report=term

# Resultado esperado (atual):
# - 48 testes
# - Tempo: ~84 segundos
# - Cobertura: ~97%
```

### Valida√ß√£o P√≥s-Otimiza√ß√£o

```bash
# Executar suite otimizada
pytest tests/ -v --durations=10 --cov=src --cov-report=term

# Resultado esperado (otimizado):
# - 20-30 testes
# - Tempo: 40-50 segundos
# - Cobertura: >= 85%
# - Menos warnings
```

### Testes de Integra√ß√£o com gpt-5-nano

**Cen√°rios Obrigat√≥rios**:

1. **Teste RN-001**: Pergunta com contexto
   - Input: Documento ingerido + pergunta relevante
   - Expected: Resposta baseada no documento (validar com assertions)

2. **Teste RN-002**: Pergunta sem contexto
   - Input: Documento ingerido + pergunta irrelevante
   - Expected: "N√£o tenho informa√ß√µes necess√°rias..."

3. **Teste RN-006**: k=10 resultados
   - Input: Query gen√©rica
   - Expected: M√°ximo 10 chunks retornados

4. **Teste E2E Completo**:
   - Input: PDF ‚Üí Ingest ‚Üí Search ‚Üí Chat
   - Expected: Fluxo completo funciona com LLM real

### M√©tricas de Sucesso

| M√©trica | Antes | Depois | Melhoria |
|---------|-------|--------|----------|
| Total de Testes | 48 | 20-30 | ~40% redu√ß√£o |
| Testes Unit√°rios | 38 | 8-10 | ~75% redu√ß√£o |
| Testes Integra√ß√£o | 10 | 15-20 | 50-100% aumento |
| Tempo Execu√ß√£o | ~84s | ~40-50s | ~40% redu√ß√£o |
| Cobertura | 97% | >= 85% | Aceit√°vel |
| Chamadas LLM | ~7 (mock) | 15-20 (real) | Real validation |
| Custo/Execu√ß√£o | $0 | ~$0.02-0.05 | M√≠nimo com gpt-5-nano |

## Documenta√ß√£o Necess√°ria

### C√≥digo

- [ ] Docstrings em novas fixtures
- [ ] Coment√°rios explicando escolhas de otimiza√ß√£o
- [ ] README de testes atualizado

### README Principal

Atualizar se√ß√£o de testes:

```markdown
## üß™ Testes

### Suite Otimizada

Nossa suite de testes foi otimizada para:
- **Foco em Integra√ß√£o**: 70% testes E2E
- **Valida√ß√£o Real**: Usa gpt-5-nano para validar comportamento
- **Performance**: Execu√ß√£o em ~40-50 segundos
- **Custo Controlado**: ~$0.02-0.05 por execu√ß√£o completa

### Executar Testes

\`\`\`bash
# Todos os testes (unit√°rios + integra√ß√£o)
pytest

# Somente unit√°rios (r√°pido, sem custo)
pytest tests/unit/ -v

# Somente integra√ß√£o (valida√ß√£o completa)
pytest tests/integration/ -v

# Com cobertura
pytest --cov=src --cov-report=html
\`\`\`

### Configura√ß√£o para Testes

\`\`\`bash
# Vari√°veis necess√°rias em .env
OPENAI_API_KEY=sk-your-key
LLM_MODEL=gpt-5-nano  # Modelo otimizado para testes
DATABASE_URL=postgresql+psycopg://postgres:postgres@localhost:5432/rag
\`\`\`
```

### Documenta√ß√£o T√©cnica

**Arquivo**: `tests/README.md`

```markdown
# Documenta√ß√£o de Testes

## Estrutura

- `unit/`: Testes unit√°rios cr√≠ticos (valida√ß√µes, erros)
- `integration/`: Testes E2E com LLM real

## Filosofia

- **Menos √© Mais**: Testes focados em valor
- **Real > Mock**: Valida√ß√£o com APIs reais
- **Fast Feedback**: Unit√°rios r√°pidos, integra√ß√£o completa

## Modelo LLM

Usamos **gpt-5-nano** para testes por:
- Custo otimizado (~10x mais barato que gpt-4)
- Velocidade adequada
- Qualidade suficiente para valida√ß√£o

## Executar

\`\`\`bash
# Unit√°rios (sem custo, < 5s)
pytest tests/unit/ -v

# Integra√ß√£o (custo m√≠nimo, ~40s)
pytest tests/integration/ -v
\`\`\`
```

## Checklist de Finaliza√ß√£o

- [ ] Suite reduzida de 48 para 20-30 testes
- [ ] Testes unit√°rios reduzidos para 8-10 (cr√≠ticos)
- [ ] Testes integra√ß√£o aumentados para 15-20
- [ ] Todos os mocks de ChatOpenAI removidos
- [ ] gpt-5-nano configurado e validado
- [ ] RN-001 validada com LLM real
- [ ] RN-002 validada com LLM real
- [ ] RN-006 validada
- [ ] Cobertura >= 85%
- [ ] Tempo execu√ß√£o <= 50 segundos
- [ ] Todos os testes passando
- [ ] README atualizado
- [ ] Documenta√ß√£o de testes criada
- [ ] M√©tricas de sucesso validadas

## Notas Adicionais

### Custo Estimado

**gpt-5-nano** (assumindo pre√ßos hipot√©ticos):
- Input: ~$0.10 / 1M tokens
- Output: ~$0.30 / 1M tokens

**Estimativa por execu√ß√£o**:
- 15-20 chamadas de LLM
- ~500 tokens input/chamada
- ~200 tokens output/chamada
- Total: ~10-15K tokens por execu√ß√£o
- **Custo: ~$0.02-0.05 por execu√ß√£o completa**

Execu√ß√µes di√°rias: 10-20
**Custo mensal estimado: $6-30** (aceit√°vel)

### Armadilhas Conhecidas

1. **Rate Limiting**: OpenAI pode limitar taxa de requisi√ß√µes
   - Solu√ß√£o: Adicionar retry com backoff

2. **Variabilidade de LLM**: Respostas podem variar
   - Solu√ß√£o: Usar assertions flex√≠veis (contains, not exact match)

3. **Tempo de Timeout**: LLM pode demorar
   - Solu√ß√£o: Timeout de 30s por teste

### Pr√≥ximas Otimiza√ß√µes (Futuro)

1. Cache de embeddings para testes
2. Fixtures com lazy loading
3. Paraleliza√ß√£o de testes de integra√ß√£o
4. Mock seletivo para desenvolvimento local

## Refer√™ncias

- [Pytest Best Practices](https://docs.pytest.org/en/stable/goodpractices.html)
- [Integration Testing Guide](https://martinfowler.com/bliki/IntegrationTest.html)
- [gpt-5-nano Documentation](https://platform.openai.com/docs/models) (verificar disponibilidade)
- [LangChain Testing](https://python.langchain.com/docs/contributing/testing)

## Exemplo de Execu√ß√£o

```bash
# 1. Limpar ambiente
docker-compose down -v
docker-compose up -d
sleep 10

# 2. Ativar venv
source .venv/bin/activate

# 3. Rodar testes otimizados
pytest tests/ -v --cov=src --cov-report=term --durations=10

# Output esperado:
# ======================== 25 passed in 45.2s =========================
# Coverage: 87%
# Slowest tests:
#   - test_rn001_answer_with_context: 3.2s
#   - test_rn002_no_context_standard_message: 2.8s
#   - test_e2e_complete_flow_with_real_llm: 4.5s
```
